{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kIIUoMvr8xPI",
        "fH-L9Sukeh5L"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Agenda\n",
        "\n",
        "- What is Large Language Model?\n",
        "- How does Large Language Models work?\n",
        "- What are the use cases of LLMs?\n",
        "- How to use LLMs effectively? (Prompt Engineering)\n",
        "- How to make LLms smarter?\n",
        "    - Give me more information (RAG)\n",
        "    - Train it more (fine-tuning)"
      ],
      "metadata": {
        "id": "ZPSPXFT-tRME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is Large Language Model?"
      ],
      "metadata": {
        "id": "ZHoQ67sgug2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The core task of the language model is next word prediction. Given a sequence of input words, the neural network predicts the probability distribution of what the next word will be.\n",
        "\n",
        "- Think of it like iPhone keyboard autocomplete\n",
        "\n",
        "- Web data (10TB) -> Training on 6k GPUs for 12 days (~$2M) -> ~140GB file\n",
        "\n",
        "- Compressing the Internet into a small file (~100x smaller)"
      ],
      "metadata": {
        "id": "zSaunicZwKot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How do Large Language Models work?"
      ],
      "metadata": {
        "id": "9Z0Eb7sAwBMT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A large neural network with billions of parameters (knobs)\n",
        "- We can measure the output, and turn the knobs to optimize performance.\n",
        "- We don't fully understand how the knobs work (blockbox)\n",
        "- Give it a prompt, and it will \"dream\" the rest of the texts"
      ],
      "metadata": {
        "id": "I4CvtjDcwO9e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What are the use cases of LLMs?"
      ],
      "metadata": {
        "id": "NMa68vC00yGf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- NLP tasks\n",
        "    - Text generation\n",
        "    - Classification\n",
        "    - Summarization\n",
        "    - Name-Entity-Recognition\n",
        "    - Question-Answering\n",
        "    - Translation\n",
        "- Higher level tasks\n",
        "    - Research\n",
        "    - Assistants"
      ],
      "metadata": {
        "id": "iZdON5la01kj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Why and why not LLMs"
      ],
      "metadata": {
        "id": "F7ukX_-U3JAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advantages and Disadvantages"
      ],
      "metadata": {
        "id": "o1HgJRMm3L8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Advantages\n",
        "\n",
        "- Versatility\n",
        "- Ability to learn new tasks\n",
        "- Large knowledge\n",
        "- Strong performance\n",
        "\n",
        "### Disadvantages\n",
        "\n",
        "- Lack of true understanding\n",
        "- Hallucination and inconsistency\n",
        "- Bias and fairness issues\n",
        "- Lack of grounding\n",
        "- Difficulty with reasoning\n",
        "- Opaque decision-making\n",
        "- Computational cost\n",
        "- Privacy and security"
      ],
      "metadata": {
        "id": "0RsyCNgc4D6P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## When to use and not to use LLMs"
      ],
      "metadata": {
        "id": "ZD6VFLgI4IVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### When to use LLMs\n",
        "\n",
        "- Creative writing\n",
        "- NLP tasks\n",
        "    - Classification\n",
        "    - Summarization\n",
        "    - Name-Entity-Recognition\n",
        "    - Question-Answering\n",
        "    - Translation\n",
        "\n",
        "### When not to use LLMs\n",
        "\n",
        "- Math\n",
        "- Logic reasoning\n",
        "- Ground truth critical tasks"
      ],
      "metadata": {
        "id": "fADQwz0w4yzK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to use LLMs effectively? (Prompt Engineering)\n",
        "\n",
        "Try all of the following prompting techniques using `OpenAI` or `Gemini` API"
      ],
      "metadata": {
        "id": "4bYSvgYP5MKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "GOOGLE_API_KEY = getpass.getpass()\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "kGnLcWyTFo9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df656425-87f3-4abb-e99e-dd561a349ca7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-pro')"
      ],
      "metadata": {
        "id": "HtLbXTfQJJ4R"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_content(prompt):\n",
        "    response = model.generate_content(prompt)\n",
        "    print(response.text)"
      ],
      "metadata": {
        "id": "KVE86s9PJPc-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Six strategies for getting better results\n",
        "\n",
        "- Write clear instructions\n",
        "- Provide reference text\n",
        "- Split complex tasks into simpler subtasks\n",
        "- Give the model time to \"think\"\n",
        "- Use external tools\n",
        "- Test changes systematically\n",
        "\n",
        "source: [OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering/strategy-write-clear-instructions)"
      ],
      "metadata": {
        "id": "hDGHQNqa6ZW1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write clear instructions"
      ],
      "metadata": {
        "id": "-8ZZsDbP60FG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# More detailed prompts\n",
        "prompt1 = \"Tell me a joke\"\n",
        "\n",
        "prompt2 = \"Tell me a joke about language. Please wirte it in two lines. Include funny emojis\"\n",
        "\n",
        "gen_content(prompt1)\n",
        "print('---------------')\n",
        "gen_content(prompt2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "YfjFYH2tJ2Zn",
        "outputId": "24adfcc9-8f62-452f-d29f-2c8d4ed9cde8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why was the math book feeling sad?\n",
            "\n",
            "Because it was full of problems!\n",
            "---------------\n",
            "What do you call a fish with no eyes? 🐟👀🐟\n",
            "Fsh!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask the model to adope a persona\n",
        "\n",
        "prompt = \"You are an expert in Python programming, please help me write a program to train a machine learning model to identify human faces\"\n",
        "gen_content(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "bi6GTG6OKPHu",
        "outputId": "023a59b6-9f4f-4f7e-dcfa-500d646eb74a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "import cv2\n",
            "import numpy as np\n",
            "from sklearn.svm import SVC\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.metrics import accuracy_score\n",
            "\n",
            "# Load the dataset\n",
            "faces = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
            "dataset = cv2.imread('dataset.jpg')\n",
            "gray = cv2.cvtColor(dataset, cv2.COLOR_BGR2GRAY)\n",
            "faces = faces.detectMultiScale(gray, 1.3, 5)\n",
            "\n",
            "# Extract the features and labels from the dataset\n",
            "features = []\n",
            "labels = []\n",
            "for (x, y, w, h) in faces:\n",
            "    roi = gray[y:y+h, x:x+w]\n",
            "    features.append(roi.flatten())\n",
            "    labels.append(1)\n",
            "\n",
            "# Create the training and testing sets\n",
            "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.25)\n",
            "\n",
            "# Train the SVM classifier\n",
            "classifier = SVC()\n",
            "classifier.fit(X_train, y_train)\n",
            "\n",
            "# Evaluate the classifier\n",
            "y_pred = classifier.predict(X_test)\n",
            "accuracy = accuracy_score(y_test, y_pred)\n",
            "print(\"Accuracy: \", accuracy)\n",
            "\n",
            "# Save the classifier\n",
            "classifier.save('face_classifier.pkl')\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use delimiters to clearly indicate the distinct parts of the input\n",
        "\n",
        "prompt = \"\"\"You are an expert in technical recruiting. Please read the following resume and job description. Give me suggestion on how to improve my resume\n",
        "\n",
        "<job description>\n",
        "Roboflow\n",
        "Product Design Intern\n",
        "Core responsibilities could include:\n",
        "\n",
        "Produce wireframes, mockups, and prototypes for new features and products\n",
        "\n",
        "Work on and expand the Ringtail Design System\n",
        "\n",
        "Identify computer vision knowledge gaps in user base and find ways to incorporate more educational context throughout the interface\n",
        "\n",
        "Conduct user research and customer studies to help deepen our understanding of pain points and opportunities of leverage\n",
        "\n",
        "Collaborate closely with our development team to architect and implement solutions\n",
        "\n",
        "Take loosely defined problems and explore various ways to tackle them\n",
        "\n",
        "Advocate for users, their needs and pain points, and weave that into smart and impactful designs\n",
        "\n",
        "We want this internship to serve you and your goals as much as you’ll be helping us. This is an experience we want to be truly collaborative and tailored as such!\n",
        "\n",
        "</job description>\n",
        "<resume>\n",
        "Cecilia\n",
        "Product Designer\n",
        "</resume>\n",
        "\"\"\"\n",
        "gen_content(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "bWJki2J5KgeL",
        "outputId": "22044f3b-51db-437d-c1e4-8e088251f590"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some suggestions on how to improve your resume to better align with the job description for the Product Design Intern role at Roboflow:\n",
            "\n",
            "**1. Highlight relevant skills and experience:**\n",
            "Emphasize your proficiency in wireframing, mockups, and prototyping. Showcase projects where you have applied these skills, providing specific examples of how you have contributed to the design process.\n",
            "\n",
            "**2. Demonstrate understanding of UX research:**\n",
            "Mention your experience in conducting user research and customer studies. Highlight your ability to identify pain points, gather insights, and translate them into actionable design solutions.\n",
            "\n",
            "**3. Emphasize collaboration and problem-solving:**\n",
            "Showcase your ability to collaborate effectively with development teams and work on cross-functional projects. Provide examples of how you have taken loosely defined problems and explored various approaches to find solutions.\n",
            "\n",
            "**4. Include examples of work that align with the company's goals:**\n",
            "Review the core responsibilities listed in the job description and tailor your resume to highlight your experience in areas such as expanding design systems, incorporating educational content, and advocating for user needs.\n",
            "\n",
            "**5. Quantify your accomplishments:**\n",
            "Whenever possible, use specific metrics and data to demonstrate the impact of your work. For example, quantify the number of users you interviewed, the number of mockups you created, or the percentage improvement in user engagement as a result of your designs.\n",
            "\n",
            "**6. Reformat your name:**\n",
            "To improve readability, consider adding your full name, \"Cecilia,\" instead of only including your first name.\n",
            "\n",
            "**7. Proofread carefully:**\n",
            "Review your resume thoroughly for any errors in grammar, spelling, or formatting. This will help create a polished and professional impression.\n",
            "\n",
            "**8. Consider tailoring your resume:**\n",
            "Once you have a strong base resume, consider tailoring it specifically to each job application. Highlight the skills and experience that are most relevant to the specific role and company you are applying to.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = \"Summarize the meeting notes.\"\n",
        "\n",
        "prompt2 = \"Summarize the meeting notes in a single paragraph. Then write a markdown list of the speakers and each of their key points. Finally, list the next steps or action items suggested by the speakers, if any.\"\n",
        "\n",
        "gen_content(prompt1)\n",
        "print('---------------')\n",
        "gen_content(prompt2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F1idzi8GNYhK",
        "outputId": "8f7d4dac-f925-4427-f54b-dd6002796a02"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Meeting Notes Summary**\n",
            "\n",
            "**Date:** [Insert Date]\n",
            "**Time:** [Insert Time]\n",
            "**Location:** [Insert Location]\n",
            "**Attendees:**\n",
            "\n",
            "* [Attendee Name]\n",
            "* [Attendee Name]\n",
            "* [Attendee Name]\n",
            "\n",
            "**Agenda Items:**\n",
            "\n",
            "**1. Project Update**\n",
            "\n",
            "* [Brief overview of project progress and milestones achieved]\n",
            "* [Any challenges or roadblocks encountered and how they were addressed]\n",
            "* [Next steps and timelines]\n",
            "\n",
            "**2. Budget Review**\n",
            "\n",
            "* [Current financial status of the project]\n",
            "* [Estimated expenditures and any variance from initial estimates]\n",
            "* [Plans to address any budget concerns]\n",
            "\n",
            "**3. Team Collaboration**\n",
            "\n",
            "* [Discussion of effective team communication and collaboration methods]\n",
            "* [Identification of areas for improvement]\n",
            "* [Implementation plan for enhancing team dynamics]\n",
            "\n",
            "**4. Customer Feedback**\n",
            "\n",
            "* [Summary of customer feedback received and analysis]\n",
            "* [Action items to address customer concerns and improve satisfaction]\n",
            "* [Plans for ongoing customer engagement]\n",
            "\n",
            "**5. Future Planning**\n",
            "\n",
            "* [Brainstorming of potential project extensions or new initiatives]\n",
            "* [Alignment of goals and objectives for the future]\n",
            "* [Resource allocation and timeline projections]\n",
            "\n",
            "**Action Items:**\n",
            "\n",
            "* [List of specific tasks assigned to attendees]\n",
            "* [Deadlines and follow-up measures]\n",
            "* [Responsibility for each action item]\n",
            "\n",
            "**Next Steps:**\n",
            "\n",
            "* [Confirmation of action items and deadlines]\n",
            "* [Schedule for follow-up meeting]\n",
            "* [Distribution of meeting notes and any relevant supporting materials]\n",
            "---------------\n",
            "**Meeting Summary:**\n",
            "\n",
            "The meeting focused on strategies for improving customer satisfaction and loyalty. A diverse group of speakers shared insights on enhancing customer experience, gathering feedback, and implementing data-driven solutions. It was recognized that personalization, omnichannel support, and a customer-centric mindset are crucial for fostering positive customer relationships.\n",
            "\n",
            "**Speakers and Key Points:**\n",
            "\n",
            "- **Speaker 1:** Emphasized the importance of personalization in customer journeys, tailoring content and recommendations to individual preferences.\n",
            "- **Speaker 2:** Highlighted the value of omnichannel support, ensuring a seamless experience across multiple channels.\n",
            "- **Speaker 3:** Advocated for proactive feedback collection, gathering customer insights through surveys, feedback forms, and social media monitoring.\n",
            "- **Speaker 4:** Stressed the significance of data analytics in identifying customer trends and optimizing strategies based on actionable insights.\n",
            "- **Speaker 5:** Shared best practices for building a customer-centric culture, where every employee understands their role in delivering exceptional experiences.\n",
            "\n",
            "**Next Steps/Action Items:**\n",
            "\n",
            "- Implement personalization strategies in customer touchpoints.\n",
            "- Enhance omnichannel support capabilities to improve customer resolution time.\n",
            "- Establish regular feedback collection mechanisms to gather customer insights.\n",
            "- Leverage data analytics to identify customer pain points and drive improvements.\n",
            "- Foster a customer-centric culture through employee training and empowerment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Include details in your query to get more relevant answers\n",
        "\n",
        "```\n",
        "Summarize the meeting notes.\n",
        "```\n",
        "\n",
        "```\n",
        "Summarize the meeting notes in a single paragraph. Then write a markdown list of the speakers and each of their key points. Finally, list the next steps or action items suggested by the speakers, if any.\n",
        "```\n",
        "\n",
        "#### Ask the model to adopt a persona\n",
        "\n",
        "```\n",
        "You are an expert in Python programming. You have 20 years of programming experience.\n",
        "```\n",
        "\n",
        "#### Use delimiters to clearly indicate distinct parts of the input\n",
        "\n",
        "```\n",
        "Summarize the text delimited by triple quotes with a haiku.\n",
        "\n",
        "\"\"\"insert text here\"\"\"\n",
        "```\n",
        "\n",
        "```\n",
        "You will be provided with a pair of articles (delimited with XML tags) about the same topic. First summarize the arguments of each article. Then indicate which of them makes a better argument and explain why.\n",
        "\n",
        "<article> insert first article here </article>\n",
        "\n",
        "<article> insert second article here </article>\n",
        "```\n",
        "\n",
        "```\n",
        "You will be provided with a thesis abstract and a suggested title for it. The thesis title should give the reader a good idea of the topic of the thesis but should also be eye-catching. If the title does not meet these criteria, suggest 5 alternatives.\n",
        "\n",
        "Abstract: insert abstract here\n",
        "\n",
        "Title: insert title here\n",
        "```\n",
        "\n",
        "#### Specify the steps required to complete a task\n",
        "Some tasks are best specified as a sequence of steps. Writing the steps out explicitly can make it easier for the model to follow them.\n",
        "\n",
        "```\n",
        "Use the following step-by-step instructions to respond to user inputs.\n",
        "\n",
        "Step 1 - The user will provide you with text in triple quotes. Summarize this text in one sentence with a prefix that says \"Summary: \".\n",
        "\n",
        "Step 2 - Translate the summary from Step 1 into Spanish, with a prefix that says \"Translation: \".\n",
        "\n",
        "\"\"\"insert text here\"\"\"\n",
        "```"
      ],
      "metadata": {
        "id": "jx8mUfWYeAyR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EUXai9MwFnP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Provide Reference Text\n",
        "\n"
      ],
      "metadata": {
        "id": "kIIUoMvr8xPI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Use the provided articles delimited by triple quotes to answer questions. If the answer cannot be found in the articles, write \"I could not find an answer.\"\n",
        "\n",
        "<insert articles, each delimited by triple quotes>\n",
        "\n",
        "Question: <insert question here>\n",
        "```\n",
        "\n",
        "#### Answer with citations from a reference text\n",
        "\n",
        "If the input has been supplemented with relevant knowledge, it's straightforward to request that the model add citations to its answers by referencing passages from provided documents. Note that citations in the output can then be verified programmatically by string matching within the provided documents.\n",
        "\n",
        "```\n",
        "You will be provided with a document delimited by triple quotes and a question. Your task is to answer the question using only the provided document and to cite the passage(s) of the document used to answer the question. If the document does not contain the information needed to answer this question then simply write: \"Insufficient information.\" If an answer to the question is provided, it must be annotated with a citation. Use the following format for to cite relevant passages ({\"citation\": …}).\n",
        "\n",
        "\"\"\"<insert document here>\"\"\"\n",
        "\n",
        "Question: <insert question here>\n",
        "```"
      ],
      "metadata": {
        "id": "e7iX2DvQedCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split complex tasks into simpler subtasks"
      ],
      "metadata": {
        "id": "fH-L9Sukeh5L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Multi-step prompting\n",
        "\n",
        "1. Write a prompt to ask the model to classify the users input\n",
        "1. Based on the ansewr from the model, choose a second prompt to complete the task\n",
        "\n",
        "Example: Customer service chatbot\n",
        "\n",
        "```\n",
        "You are a complaint categorizer. Based on the users input and the following criteria, please output the category of the users inquery.\n",
        "```\n",
        "\n",
        "A: troubleshooting\n",
        "\n",
        "```\n",
        "You are a customer service agent. Please provide helpful instruction to help the user troubleshoot the product.\n",
        "```"
      ],
      "metadata": {
        "id": "eMp_60TTeuAr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Summarization\n",
        "\n",
        "**Summarize conversations that's too long**\n",
        "\n",
        "LLMs have limited context window lengths. For long conversations that requires context preservation, consider summarize the previous conversation and start new conversation. (GPT-4 16k or 32k)\n",
        "\n",
        "**Chunk long texts then summarize recursively**\n",
        "\n",
        "Chunk longs texts (a book) into reasonably sized tokens (1024, 2048, 4906 tokens, experiemnt with them) then summarize recusively to produce summary of summaries.\n",
        "\n",
        "You can consider running (refine) strategy for summarization"
      ],
      "metadata": {
        "id": "CMi_c4l3fqhE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Give model time to think"
      ],
      "metadata": {
        "id": "iBXxrDzzhGMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Read the following JD and resume, do the following tasks\n",
        "1. Output \"good fit\" or \"not good fit\"\n",
        "2. Give the strengh and weaknesses of the candidate for this job\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "Read the following JD and resume, do the following tasks\n",
        "1. Give the strengh and weaknesses of the candidate for this job\n",
        "2. Output \"good fit\" or \"not good fit\"\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "dNtIiQP1AbHq",
        "outputId": "5f4e72fe-b9ef-4f96-f2e5-318acbfcf561"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nRead the following JD and resume, do the following tasks\\n1. Give the strengh and weaknesses of the candidate for this job\\n2. Output \"good fit\" or \"not good fit\"\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chain of thought**\n",
        "\n",
        "The order of output matters.\n",
        "\n",
        "Ask the model to think and layout the strategy first before outputting the final decision.\n",
        "\n",
        "**Inner monologue to hide chain of thoughts**\n",
        "\n",
        "Ask the model to output the intermediate thoughts in a structured format (such as \"\"\" triple quotes) that's easy to parsed in a post procesisng step.\n",
        "\n",
        "**multi step prompting**\n",
        "\n",
        "In a evaluation or reasoning task\n",
        "\n",
        "- Ask the model to perform task on it's own\n",
        "- Evaluate the users input\n",
        "- (Bonus) Ask a different persona to give final verdict"
      ],
      "metadata": {
        "id": "CSK-_Xj2hIaL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### User External Tools"
      ],
      "metadata": {
        "id": "L07wK_6-iMZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Search for relevent information and inject into context**\n",
        "\n",
        "- Vector searching using embeddings\n",
        "- Google search\n",
        "\n",
        "**Ask model to generate code**\n",
        "\n",
        "```\n",
        "You can write and execute Python code by enclosing it in triple backticks, e.g. ```code goes here```. Use this to perform calculations.\n",
        "\n",
        "Find all real-valued roots of the following polynomial: 3*x**5 - 5*x**4 - 3*x**3 - 7*x - 10.\n",
        "```\n",
        "\n",
        "```\n",
        "You can write and execute Python code by enclosing it in triple backticks. Also note that you have access to the following module to help users send messages to their friends:\n",
        "\n",
        "```python\n",
        "import message\n",
        "message.write(to=\"John\", message=\"Hey, want to meetup after work?\")```\n",
        "```\n",
        "\n",
        "It's dangerous to run model generated code without sandboxing.\n",
        "\n",
        "Consider using [function calling](https://platform.openai.com/docs/guides/function-calling) instead"
      ],
      "metadata": {
        "id": "Xf9n2ZeiiOwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "def get_weather(location_name):\n",
        "    weather = requests.get(location_name)\n",
        "    return weather\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "You have access to this function, here is the function definition\n",
        "\n",
        "{\n",
        "    \"function_name\": \"get_weather\",\n",
        "    \"arguments: [\n",
        "        \"location_name\": \"this is the name of the location to search for the weather\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "Questions: What is the weather in Seattle?\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "get_weather(\"Seattle\")\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ShI_lWD3DINW",
        "outputId": "186bbb16-48ea-4752-e8c0-186105abb2b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nget_weather(\"Seattle\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "## Documents\n",
        "\n",
        "- [Steven Wolfram's intro to LLM](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/)\n",
        "- [Mistral AI docs](https://docs.mistral.ai/guides/resources/)\n",
        "- [OpenAI Prompt Engineering](https://platform.openai.com/examples)\n",
        "- [Elastic's intro to LLM](https://www.elastic.co/what-is/large-language-models)\n",
        "\n",
        "## Youtube\n",
        "\n",
        "- [Awesome talk by Andrej Karpathy](https://youtu.be/zjkBMFhNj_g?si=wPxLgMJ2D-CZsQvv)\n",
        "- [Large Language Models](https://www.youtube.com/watch?v=YDiSFS-yHwk)\n",
        "\n",
        "## Colab Notebooks\n",
        "\n",
        "- https://colab.research.google.com/drive/1uQABWrbU17DwLQdDZ8k5d_UJVlrAkwZ5?usp=sharing\n",
        "\n",
        "## GitHub\n",
        "\n",
        "- https://github.com/mlabonne/llm-course\n",
        "\n",
        "- https://github.com/datainsightat/introduction_llm\n",
        "\n",
        "- https://github.com/Ryota-Kawamura/Generative-AI-with-LLMs/tree/main\n",
        "\n",
        "- https://github.com/sinanuozdemir/oreilly-hands-on-transformers\n",
        "\n",
        "- https://github.com/gkamradt/langchain-tutorials\n",
        "\n",
        "- https://github.com/openai/openai-cookbook\n",
        "\n",
        "- https://github.com/dair-ai/Prompt-Engineering-Guide\n",
        "\n",
        "- https://github.com/ksm26/chatGPT-Prompt-Engineering-for-Developers\n",
        "\n",
        "- https://github.com/kevinamiri/Instructgpt-prompts\n",
        "\n",
        "- https://github.com/promptslab/Promptify\n",
        "\n",
        "- https://github.com/dair-ai/Prompt-Engineering-Guide\n",
        "\n",
        "## Papers\n",
        "\n",
        "- [Attention is all you need](https://arxiv.org/abs/1706.03762)\n",
        "- [FINETUNED LANGUAGE MODELS ARE ZERO-SHOT LEARNERS](https://openreview.net/pdf?id=gEZrGCozdqR)\n",
        "- [Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165)"
      ],
      "metadata": {
        "id": "RA64OmGW6LEL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eHpT2dBBj0Zl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}